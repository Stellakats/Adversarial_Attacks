{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adversarial Training!\n",
    "\n",
    "[Towards Deep Learning Models Resistant to Adversarial Attacks](https://arxiv.org/abs/1706.06083)\n",
    "\n",
    "Introduce a dual optimization process (not guaranteed to increase robustness); fit network parameters $\\theta$ so that \n",
    "\n",
    "$$\n",
    "\\min_\\theta \\mathbb{E}_{(x,y) \\sim \\mathcal{D}} \\left[ \\max_{\\delta \\in \\mathcal{S}} L(\\theta, x+\\delta, y) \\right]\n",
    "$$\n",
    "\n",
    "where $\\mathcal{S}$ is the box around the input images $(x, y) \\sim \\mathcal{D}$ where we want to avoid for adversarial attacks (in this case, we'll use the infinity box),  and $L$ is a kind of attack metric that we want to increase (we'll be using PGD to increase the cross entropy loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np\n",
    "import time \n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cpu\") # I'm not sure if it will work out of the box with cuda even if you have a GPU\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed():\n",
    "    np.random.seed(42)\n",
    "    torch.manual_seed(42)\n",
    "\n",
    "seed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc = nn.Linear(28*28, 200)\n",
    "        self.fc2 = nn.Linear(200, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view((-1, 28*28))\n",
    "        x = F.relu(self.fc(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.MNIST(\n",
    "    'mnist_data/', train=True, download=True, transform=transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    "))\n",
    "\n",
    "test_dataset = datasets.MNIST(\n",
    "    'mnist_data/', train=False, download=True, transform=transforms.Compose(\n",
    "    [transforms.ToTensor()]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset, batch_size=batch_size, shuffle=True\n",
    ")\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset, batch_size=batch_size, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Normalize(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return (x - 0.1307)/0.3081 # expectation and standard deviation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attack\n",
    "\n",
    "There is one difference now compared to the attacking notebook: before the attack, the image is displaced a to a random location within the infinity ball of radius eps around the input image. This makes it possible for the attack to find more local minimia within the infinity ball, and thus enables a better defence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pgd_untargeted(\n",
    "    model, \n",
    "    x, \n",
    "    labels, \n",
    "    k, \n",
    "    epsilon, \n",
    "    epsilon_step, \n",
    "    clamp_min=None, \n",
    "    clamp_max=None,\n",
    "    **kwargs\n",
    "):\n",
    "    \"\"\"Attack for adversarial training. Modifies input within infinity ball\n",
    "    \n",
    "        labels - true label\n",
    "        k - attack iterations\n",
    "        epsilon - |x - out| <= epsilon\n",
    "        epsilon_step - step size\n",
    "        clamps - are allowed range on image feature\n",
    "    \"\"\"\n",
    "    x_min = x - epsilon\n",
    "    x_max = x + epsilon\n",
    "    \n",
    "    img = torch.as_tensor(x, device=device)\n",
    "    img += epsilon * torch.rand_like(img)\n",
    "    img.requires_grad = True\n",
    "    \n",
    "    for i in range(k):\n",
    "        model.zero_grad()\n",
    "        nn.CrossEntropyLoss()(model(img), labels).backward()\n",
    "        img = img + (epsilon_step * img.grad.sign())\n",
    "        img = torch.min(x_max, torch.max(x_min, img))\n",
    "        \n",
    "        img = torch.as_tensor(img.data, device=device)\n",
    "        img.requires_grad = True\n",
    "        \n",
    "    return img.clamp(clamp_min, clamp_max) if not clamp_min is None else img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Would be interesting to test different values \n",
    "# Plot accurace with and without attack and training\n",
    "\n",
    "DEFAULT_ATTACK_KWARGS = {\n",
    "    'k': 5, \n",
    "    'epsilon': 0.2,          \n",
    "    'epsilon_step': 0.05,\n",
    "    'clip_min': 0,\n",
    "    'clip_max': 1,\n",
    "}\n",
    "\n",
    "def fit(\n",
    "    model,\n",
    "    learning_rate=0.0001,\n",
    "    num_epochs=5,\n",
    "    attack_kwargs=DEFAULT_ATTACK_KWARGS.copy()\n",
    "):\n",
    "    opt = optim.Adam(params=model.parameters(), lr=learning_rate)\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        t1 = time.time()\n",
    "\n",
    "        for x_batch, y_batch in train_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            if attack_kwargs is not None:\n",
    "                model.eval()\n",
    "                x_batch = pgd_untargeted(model, x_batch, y_batch, **attack_kwargs)\n",
    "                model.train()\n",
    "\n",
    "            opt.zero_grad()\n",
    "            out = model(x_batch)\n",
    "            batch_loss = ce_loss(out, y_batch)\n",
    "            batch_loss.backward()\n",
    "            opt.step()\n",
    "\n",
    "        tested_count, correct_count = 0.0, 0.0\n",
    "        model.eval()\n",
    "        for x_batch, y_batch in test_loader:\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "            out = model(x_batch)\n",
    "            pred = torch.max(out, dim=1)[1]\n",
    "            acc = pred.eq(y_batch).sum().item()\n",
    "            correct_count += acc\n",
    "            tested_count += x_batch.size()[0]\n",
    "\n",
    "        t2 = time.time()\n",
    "\n",
    "        print('Epoch %d: Accuracy %.5lf [%.2lf seconds]' % (epoch+1, correct_count/tested_count, t2-t1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Accuracy 0.91770 [7.50 seconds]\n",
      "Epoch 2: Accuracy 0.93580 [7.90 seconds]\n",
      "Epoch 3: Accuracy 0.94740 [8.03 seconds]\n",
      "Epoch 4: Accuracy 0.95440 [8.07 seconds]\n",
      "Epoch 5: Accuracy 0.95870 [8.09 seconds]\n"
     ]
    }
   ],
   "source": [
    "seed()\n",
    "model = nn.Sequential(Normalize(), Net()).to(device)\n",
    "fit(model, attack_kwargs=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Accuracy 0.74430 [16.27 seconds]\n",
      "Epoch 2: Accuracy 0.85380 [16.77 seconds]\n",
      "Epoch 3: Accuracy 0.89360 [17.59 seconds]\n",
      "Epoch 4: Accuracy 0.91340 [19.51 seconds]\n",
      "Epoch 5: Accuracy 0.92130 [17.67 seconds]\n"
     ]
    }
   ],
   "source": [
    "seed()\n",
    "pgdmodel = nn.Sequential(Normalize(), Net()).to(device)\n",
    "fit(pgdmodel)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Is the robustness increased? Yes it is! :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 10])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x, y = next(iter(train_loader))\n",
    "\n",
    "out = model(x)\n",
    "\n",
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = 5\n",
    "epsilon = 0.2\n",
    "epsilon_step = 0.05\n",
    "\n",
    "def accuracy_under_attack(\n",
    "    model,\n",
    "    data_loader,\n",
    "    attack\n",
    "):\n",
    "    model.eval()\n",
    "    tot_test, tot_acc = 0.0, 0.0\n",
    "    for x_batch, y_batch in data_loader:\n",
    "        x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "        \n",
    "        if attack:\n",
    "            x_batch = pgd_untargeted(\n",
    "                model,\n",
    "                x_batch,\n",
    "                y_batch,\n",
    "                clip_min=0,\n",
    "                clip_max=1,\n",
    "                k=k,\n",
    "                epsilon=epsilon,\n",
    "                epsilon_step=epsilon_step,\n",
    "            )\n",
    "        \n",
    "        out = model(x_batch)\n",
    "        pred = torch.max(out, dim=1)[1]\n",
    "        \n",
    "        tot_acc += pred.eq(y_batch).sum().item()\n",
    "        tot_test += x_batch.size()[0]\n",
    "        \n",
    "    return tot_acc/tot_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=124, shuffle=False)\n",
    "\n",
    "df = pd.DataFrame(columns=['Net', 'Natural', 'PGD attack'])\n",
    "df.loc[len(df), :] = ('Vanilla net',\n",
    "        accuracy_under_attack(model, test_loader, False),\n",
    "        accuracy_under_attack(model, test_loader,  True)\n",
    ")\n",
    "\n",
    "df.loc[len(df), :] = ('PGD trained',\n",
    "        accuracy_under_attack(pgdmodel, test_loader, False),\n",
    "        accuracy_under_attack(pgdmodel, test_loader,  True)\n",
    ")\n",
    "\n",
    "df = 100*df.set_index('Net')\n",
    "df[' '] = \"%\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Adversarially trained network performs better under attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Natural</th>\n",
       "      <th>PGD attack</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Net</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Vanilla net</th>\n",
       "      <td>95.87</td>\n",
       "      <td>0.05</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PGD trained</th>\n",
       "      <td>92.13</td>\n",
       "      <td>55.89</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Natural PGD attack   \n",
       "Net                              \n",
       "Vanilla net   95.87       0.05  %\n",
       "PGD trained   92.13      55.89  %"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loss distribution: The loss is more tightly concentrated around zero for adversarially trained networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_attacks = int(1e4)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "x, y = next(iter(test_loader))\n",
    "x = torch.cat([torch.as_tensor(x) for i in range(number_of_attacks)], 0).to(device)\n",
    "y = torch.cat([torch.as_tensor(y) for i in range(number_of_attacks)], 0).to(device)\n",
    "\n",
    "advx = pgd_untargeted(model, x, y, 5, 0.2, 0.05, 0, 1)\n",
    "ce_loss = torch.nn.CrossEntropyLoss(reduction='none')\n",
    "\n",
    "loss = ce_loss(model(advx), y).cpu().detach().numpy()\n",
    "advloss = ce_loss(pgdmodel(advx), y).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "f, ax = plt.subplots()\n",
    "\n",
    "ax.hist(loss, label=\"Vanilla\")\n",
    "ax.hist(advloss, label=\"PGD trained\")\n",
    "\n",
    "ax.legend(loc='best')\n",
    "ax.set_yscale('log')\n",
    "\n",
    "ax.set_xlabel('Loss')\n",
    "ax.set_ylabel('Count')\n",
    "\n",
    "plt.title(\"The advarsarially trained network has more concentrated losses!\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
